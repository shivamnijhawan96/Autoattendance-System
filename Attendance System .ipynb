{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUTOMATED ATTENDANCE SYSTEM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                                    MADE BY:\n",
    "                                                    \n",
    "                                               -Shivam (1510991611)     \n",
    "                                               -Tanmay (1510991673)\n",
    "                                               -Tanya (1510991677)\n",
    "                                               -Vishal (1510991730)\n",
    "                                               \n",
    "                                               \n",
    "                                                                       ...in chronogical order of the respective roll numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BUILDING THE DATABASE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following chunk of code was used to build the database, with its schema."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import sys \n",
    "from sqlalchemy import Column, ForeignKey,Integer,String\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import relationship\n",
    "from sqlalchemy import create_engine\n",
    "Base = declarative_base()\n",
    "class Attendance(Base):\n",
    "    __tablename__ = 'attendance_record'\n",
    "\n",
    "    name = Column(String(80))\n",
    "    attend = Column(String(5))\n",
    "    roll_no = Column(String(12),primary_key=True)\n",
    "    \n",
    "\n",
    "engine = create_engine('sqlite:///attendance.db')\n",
    "Base.metadata.create_all(engine)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORTS ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a pre-execution step, we have to decide which libraries we have to use for execution.\n",
    "\n",
    "1. We have used SQLAlchemy for an Object Relational Mapping of the table in our database.\n",
    "2. We build a session and create a sqlite engine as connection for the table.\n",
    "\n",
    "- We import sklearn for KNNClassifier, which is the backbone of our algorithm.\n",
    "- We import PIL for imagery.\n",
    "- We import face_recognition (a dlib based interface for face_recognition). It has all the features of OpenCV face recognition and more, with support for many ways to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "\n",
    "from db import Attendance, Base\n",
    "\n",
    "engine = create_engine('sqlite:///attendance.db')\n",
    "Base.metadata.bind = engine\n",
    "DBSession = sessionmaker(bind=engine)\n",
    "session = DBSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import math\n",
    "from sklearn import neighbors\n",
    "import os\n",
    "import os.path\n",
    "import pickle\n",
    "from PIL import Image, ImageDraw\n",
    "import face_recognition\n",
    "from face_recognition.face_recognition_cli import image_files_in_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We allow image type to be either of png or jpeg format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ALLOWED_EXTENSIONS = {'png', 'jpg', 'jpeg'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the face detection classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, coming to training the classifier:\n",
    "face_recognition, one of the libraries used works for a heirarchy of folders.\n",
    "\n",
    "The train directory contains the subdirectories labeled as the names of the individuals. We have used _ as a seperator between names and roll numbers.\n",
    "The subdirectories contain the images, on which there is no labeling constraint.\n",
    "\n",
    "Trains a k-nearest neighbors classifier for face recognition.\n",
    "\n",
    "     Structure:\n",
    "        <train_dir>/\n",
    "        ├── <person1>/\n",
    "        │   ├── <somename1>.jpeg\n",
    "        │   ├── <somename2>.jpeg\n",
    "        │   ├── ...\n",
    "        ├── <person2>/\n",
    "        │   ├── <somename1>.jpeg\n",
    "        │   └── <somename2>.jpeg\n",
    "        └── ...\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- param train_dir: directory that contains a sub-directory for each known person, with its name.\n",
    "\n",
    "- param model_save_path: (optional) path to save model on disk\n",
    "\n",
    "- param n_neighbors: (optional) number of neighbors to weigh in classification. Chosen automatically if not specified\n",
    "\n",
    "- param knn_algo: (optional) underlying data structure to support knn.default is ball_tree\n",
    "\n",
    "- param verbose: verbosity of training\n",
    "\n",
    "- return: returns knn classifier that was trained on the given data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We:\n",
    "- Loop through each person in the training set\n",
    "- Loop through each training image for the current person\n",
    "- If there are no people (or too many people) in a training image, skip the image.\n",
    "- Add face encoding for current image to the training set\n",
    "- Determine how many neighbors to use for weighting in the KNN classifier\n",
    "- Create and Save the trained KNN classifier\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(train_dir, model_save_path=None, n_neighbors=None, knn_algo='ball_tree', verbose=False):\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for class_dir in os.listdir(train_dir):\n",
    "        if not os.path.isdir(os.path.join(train_dir, class_dir)):\n",
    "            continue\n",
    "\n",
    "        for img_path in image_files_in_folder(os.path.join(train_dir, class_dir)):\n",
    "            image = face_recognition.load_image_file(img_path)\n",
    "            face_bounding_boxes = face_recognition.face_locations(image)\n",
    "\n",
    "            if len(face_bounding_boxes) != 1:\n",
    "                if verbose:\n",
    "                    print(\"Image {} not suitable for training: {}\".format(img_path, \"Didn't find a face\" if len(face_bounding_boxes) < 1 else \"Found more than one face\"))\n",
    "            else:\n",
    "                X.append(face_recognition.face_encodings(image, known_face_locations=face_bounding_boxes)[0])\n",
    "                y.append(class_dir)\n",
    "\n",
    "    if n_neighbors is None:\n",
    "        n_neighbors = int(round(math.sqrt(len(X))))\n",
    "        if verbose:\n",
    "            print(\"Chose n_neighbors automatically:\", n_neighbors)\n",
    "\n",
    "    knn_clf = neighbors.KNeighborsClassifier(n_neighbors=n_neighbors, algorithm=knn_algo, weights='distance')\n",
    "    knn_clf.fit(X, y)\n",
    "\n",
    "    if model_save_path is not None:\n",
    "        with open(model_save_path, 'wb') as f:\n",
    "            pickle.dump(knn_clf, f)\n",
    "\n",
    "    return knn_clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FROM NEAREST NEIGHBOUR MODELLING TO MAKING PREDICTIONS\n",
    "\n",
    "\n",
    "\n",
    "Recognizes faces in given image using a trained KNN classifier\n",
    "\n",
    "    :param X_img_path: path to image to be recognized\n",
    "    :param knn_clf: (optional) a knn classifier object. if not specified, model_save_path must be specified.\n",
    "    :param model_path: (optional) path to a pickled knn classifier. if not specified, model_save_path must be knn_clf.\n",
    "    :param distance_threshold: (optional) distance threshold for face classification. the larger it is, the more chance\n",
    "           of mis-classifying an unknown person as a known one.\n",
    "    :return: a list of names and face locations for the recognized faces in the image: [(name, bounding box), ...].\n",
    "        For faces of unrecognized persons, the name 'unknown' will be returned.\n",
    "\n",
    "Here, we:\n",
    "- Load a trained KNN model (if one was passed in)\n",
    "- Load image file and find face locations\n",
    "- If no faces are found in the image, return an empty result.\n",
    "- Find encodings for faces in the test iamge\n",
    "- Use the KNN model to find the best matches for the test face\n",
    "- Predict classes and remove classifications that aren't within the threshold\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(X_img_path, knn_clf=None, model_path=None, distance_threshold=0.6):\n",
    "    if not os.path.isfile(X_img_path) or os.path.splitext(X_img_path)[1][1:] not in ALLOWED_EXTENSIONS:\n",
    "        raise Exception(\"Invalid image path: {}\".format(X_img_path))\n",
    "\n",
    "    if knn_clf is None and model_path is None:\n",
    "        raise Exception(\"Must supply knn classifier either thourgh knn_clf or model_path\")\n",
    "\n",
    "    if knn_clf is None:\n",
    "        with open(model_path, 'rb') as f:\n",
    "            knn_clf = pickle.load(f)\n",
    "\n",
    "    X_img = face_recognition.load_image_file(X_img_path)\n",
    "    X_face_locations = face_recognition.face_locations(X_img)\n",
    "\n",
    "    if len(X_face_locations) == 0:\n",
    "        return []\n",
    "\n",
    "    faces_encodings = face_recognition.face_encodings(X_img, known_face_locations=X_face_locations)\n",
    "\n",
    "    closest_distances = knn_clf.kneighbors(faces_encodings, n_neighbors=1)\n",
    "    are_matches = [closest_distances[0][i][0] <= distance_threshold for i in range(len(X_face_locations))]\n",
    "\n",
    "    return [(pred, loc) if rec else (\"unknown\", loc) for pred, loc, rec in zip(knn_clf.predict(faces_encodings), X_face_locations, are_matches)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHOW LABELS\n",
    "\n",
    "Shows the face recognition results visually.\n",
    "\n",
    ":param img_path: path to image to be recognized\n",
    ":param predictions: results of the predict function\n",
    ":return:\n",
    "\n",
    "- Draw a box around the face using the Pillow module\n",
    "- There's a bug in Pillow where it blows up with non-UTF-8 text when using the default bitmap font\n",
    "- Draw a label with a name below the face\n",
    "- Remove the drawing library from memory as per the Pillow docs\n",
    "- Display the resulting image\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_prediction_labels_on_image(img_path, predictions):\n",
    "    \n",
    "    pil_image = Image.open(img_path).convert(\"RGB\")\n",
    "    draw = ImageDraw.Draw(pil_image)\n",
    "\n",
    "    for name, (top, right, bottom, left) in predictions:\n",
    "        draw.rectangle(((left, top), (right, bottom)), outline=(0, 0, 255))\n",
    "\n",
    "        name = name.encode(\"UTF-8\")\n",
    "\n",
    "        text_width, text_height = draw.textsize(name)\n",
    "        draw.rectangle(((left, bottom - text_height - 10), (right, bottom)), fill=(0, 0, 255), outline=(0, 0, 255))\n",
    "        draw.text((left + 6, bottom - text_height - 5), name, fill=(255, 255, 255, 255))\n",
    "\n",
    "    del draw\n",
    "\n",
    "    pil_image.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COMBINING IT ALL: EXECUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STEP 1: Train the KNN classifier and save it to disk\n",
    " Once the model is trained and saved, you can skip this step next time.\n",
    "#### STEP 2: Using the trained classifier, make predictions for unknown images\n",
    "  Find all people in the image using a trained classifier model\n",
    "  Note: You can pass in either a classifier file name or a classifier model instance\n",
    "  Print results on the console\n",
    "#### STEP 3: Show labeled predictions on  images \n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training KNN classifier...\n",
      "Training complete!\n",
      "Looking for faces in WIN_20180519_01_57_50_Pro.jpg\n",
      "- Found navroop_1510991401 at (706, 142)\n",
      "- Found tanmay_1510991673 at (324, 325)\n",
      "['navroop_1510991401', 'tanmay_1510991673']\n",
      "[]\n",
      "['1510991401', '1510991673']\n",
      "Looking for faces in WIN_20180519_10_46_10_Pro (2).jpg\n",
      "- Found tanmay_1510991673 at (588, 316)\n",
      "- Found shivam_1510991611 at (902, 242)\n",
      "- Found vishal_1510991730 at (411, 225)\n",
      "['tanmay_1510991673', 'shivam_1510991611', 'vishal_1510991730']\n",
      "[]\n",
      "['1510991673', '1510991611', '1510991730']\n",
      "Looking for faces in WIN_20180519_11_10_37_Pro.jpg\n",
      "- Found tanmay_1510991673 at (772, 235)\n",
      "- Found vishal_1510991730 at (562, 270)\n",
      "- Found shivam_1510991611 at (268, 282)\n",
      "- Found tanya_1510991677 at (1010, 305)\n",
      "['tanmay_1510991673', 'vishal_1510991730', 'shivam_1510991611', 'tanya_1510991677']\n",
      "[]\n",
      "['1510991673', '1510991730', '1510991611', '1510991677']\n",
      "Looking for faces in WIN_20180519_13_32_49_Pro.jpg\n",
      "- Found tanmay_1510991673 at (266, 266)\n",
      "- Found mam at (786, 339)\n",
      "['tanmay_1510991673', 'mam']\n",
      "[]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-3300530a0095>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m             \u001b[0m_\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'_'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m             \u001b[0mpresent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpresent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(\"Training KNN classifier...\")\n",
    "    classifier = train(\"knn_examples/train\", model_save_path=\"trained_knn_model.clf\", n_neighbors=2)\n",
    "    print(\"Training complete!\")\n",
    "\n",
    "    for image_file in os.listdir(\"knn_examples/test\"):\n",
    "        full_file_path = os.path.join(\"knn_examples/test\", image_file)\n",
    "\n",
    "        print(\"Looking for faces in {}\".format(image_file))\n",
    "\n",
    "        predictions = predict(full_file_path, model_path=\"trained_knn_model.clf\")\n",
    "        \n",
    "        preds=[]\n",
    "        for name, (top, right, bottom, left) in predictions:\n",
    "            preds.append(name)\n",
    "            print(\"- Found {} at ({}, {})\".format(name, left, top))\n",
    "        print(preds)\n",
    "        \n",
    "        students  = []\n",
    "        present = []\n",
    "        \n",
    "        students_db = session.query(Attendance).all()\n",
    "        for s in students_db:\n",
    "            students.append(s.roll_no)\n",
    "        print(students)\n",
    "        \n",
    "        for i in preds:\n",
    "            _= i.split('_')[1]\n",
    "            present.append(_)\n",
    "        print(present)\n",
    "        \n",
    "        for i in students:\n",
    "            \n",
    "            if i in present:\n",
    "                #print('Present',i)\n",
    "                x = session.query(Attendance).filter_by(roll_no=i).first()\n",
    "                \n",
    "                x.attend = 1\n",
    "                \n",
    "                if(x.attend)>=1:\n",
    "                    x.attend += 1\n",
    "                session.add(x)\n",
    "                #s1 = Attendance(attend='1',roll_no=i)\n",
    "                #session.add(s1)\n",
    "        session.commit()\n",
    "        show_prediction_labels_on_image(os.path.join(\"knn_examples/test\", image_file), predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONCLUSION\n",
    "\n",
    "\n",
    "Through this, we can conclude that:\n",
    "- It is fairly easy to o face detection and recognition, with a pre-existing database for trained and testing images.\n",
    "- KNN uses a nearest neighbour approach, which helps as a metric (distance), from which we can deduce the accuracy of the match between the trained and tested image, with the same detection.\n",
    "- This is an intelligent approach for feature detection and recognition, in which, we compare the face encodings of the two images to be compared. \n",
    "\n",
    "\n",
    "The face encodings are an appropriate measure to compare the most important features of the cropped face (enclosed within the bounding box), and they are compared using a measure of _'euclidean distance'_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
